{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ijGzTHJJUCPY"
      },
      "outputs": [],
      "source": [
        "# Copyright 2023 Google LLC\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VEqbX8OhE8y9"
      },
      "source": [
        "# Primeros Pasos con Vertex AI Gemini API & Python SDK\n",
        "\n",
        "<table align=\"left\">\n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://colab.research.google.com/github/GoogleCloudPlatform/generative-ai/blob/main/gemini/getting-started/intro_gemini_python.ipynb\">\n",
        "      <img src=\"https://cloud.google.com/ml-engine/images/colab-logo-32px.png\" alt=\"Google Colaboratory logo\"><br> Ejecutar en Colab\n",
        "    </a>\n",
        "  </td>\n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/getting-started/intro_gemini_python.ipynb\">\n",
        "      <img src=\"https://cloud.google.com/ml-engine/images/github-logo-32px.png\" alt=\"GitHub logo\"><br> Ver en GitHub\n",
        "    </a>\n",
        "  </td>\n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https://raw.githubusercontent.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/getting-started/intro_gemini_python.ipynb\">\n",
        "      <img src=\"https://lh3.googleusercontent.com/UiNooY4LUgW_oTvpsNhPpQzsstV5W8F7rYgxgGBD85cWJoLmrOzhVs_ksK_vgx40SHs7jCqkTkCk=e14-rj-sc0xffffff-h130-w32\" alt=\"Vertex AI logo\"><br> Abrir en Workbench de Vertex AI\n",
        "    </a>\n",
        "  </td>\n",
        "</table>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CkHPv2myT2cx"
      },
      "source": [
        "## Visión General\n",
        "\n",
        "### Gemini\n",
        "\n",
        "Gemini es una familia de modelos generativos de IA desarrollados por Google DeepMind y proyectados para casos de uso multimodales. La API Gemini da acceso a los modelos Gemini Pro Vision y Gemini Pro\n",
        "\n",
        "\n",
        "### API Vertex AI Gemini\n",
        "\n",
        "La API Vertex AI Gemini nos da una interface unificada para interactuar com modelos Gemini. Actualmente existen dos modelos disponíbles en la API Gemini:\n",
        "\n",
        "\n",
        "- **Modelo Gemini Pro** (`gemini-pro`): Proyectado para manejar tareas de lenguage natural, chat multiturno de texto y código y generación de código.\n",
        "- **Modelo Gemini Pro Vision** (`gemini-pro-vision`): Soporta prompts multimodales. Puedes incluir texto, imágenes y video en los prompt y obtener respuestas en texto o código.\n",
        "\n",
        "Puedes interactuar con la API Gemini usando los siguiente métodos:\n",
        "\n",
        "- Usando [Vertex AI Studio](https://cloud.google.com/generative-ai-studio) para pruebas rápidos y generación de comandos.\n",
        "- Usando el SDK de Vertex AI\n",
        "\n",
        "Este notebook se concntra en el uso de **Vertex AI SDK para Python** para utilizar la API Vertex AI Gemini.\n",
        "\n",
        "Para obtener más inforción, consulte la documentación [IA Generativa en Vertex AI](https://cloud.google.com/vertex-ai/docs/generative-ai/learn/overview)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DrkcqHrrwMAo"
      },
      "source": [
        "### Objetivos\n",
        "\n",
        "En este tutorual, aprenderás como usar la API Vertex AI Gemini con el SDK Vertex AI para Python para interactuar con los modelos Gemini Pro (`gemini-pro`) y Gemini Pro Vision (`gemini-pro-vision`).\n",
        "\n",
        "Concluiras las siguientes tareas:\n",
        "\n",
        "- Instalar el SDK de Vertex AI para Python\n",
        "- Usar la API Vertex AI Gemini para interactuar con cada modelo\n",
        "  - Modelo Gemini Pro (`gemini-pro`):\n",
        "    - Genera textos a partir de prompts de texto.\n",
        "    - Exploa varios recursos y opciones de configuración.\n",
        "  -  Modelo Gemini Pro Vision (`gemini-pro-vision`):\n",
        "    - Genera texto a partir de imágenes y prompts de texto.\n",
        "    - Genera texto a partit de prompts de video y texto.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C9nEPojogw-g"
      },
      "source": [
        "### Costos\n",
        "\n",
        "Este tutorial usa los siguientes componentes de Google Cloud que pueden generar costos en su factura:\n",
        "\n",
        "- Vertex AI\n",
        "\n",
        "Para mayores detalles puedes revisar los [precios de Vertex AI](https://cloud.google.com/vertex-ai/pricing) y usar la [calculadora de precios](https://cloud.google.com/products/calculator/) para generar una estimativa de costos con base en el uso del proyecto."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r11Gu7qNgx1p"
      },
      "source": [
        "## Primeros pasos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "No17Cw5hgx12"
      },
      "source": [
        "### Instala el SDK de Vertex AI\n",
        "**Importante:** solo descomente la siguiente línea si **no estas** ejecutando este laboratório en Qwiklabs (Skills Boost)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tFy3H3aPgx12",
        "scrolled": true,
        "tags": []
      },
      "outputs": [],
      "source": [
        "# ! pip3 install --upgrade --user google-cloud-aiplatform"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j7UyNVSiyQ96",
        "tags": []
      },
      "source": [
        "### **Reinicie el kernel de su jupyter notebook**\n",
        "\n",
        "Como la instalción está siendo realizada con la opción `--user` es necesario reiniciar el kernel para que los nuevos módulos se tornen accesibles.\n",
        "\n",
        "**Importante:** solo descomente las siguientes lineas si **não estiver** ejecutando este laboratório en Qwiklabs (Skills Boost)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YmY9HVVGSBW5",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# import IPython\n",
        "\n",
        "# app = IPython.Application.instance()\n",
        "# app.kernel.do_shutdown(True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aq04FNCSQp7L"
      },
      "source": [
        "<div class=\"alert alert-block alert-warning\">\n",
        "<b>⚠️ El kernel del notebook está siendo reiniciado. Por favor espere que este proceso sea finalizado para poder continuar con los próximos pasos. ⚠️</b>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dmWOrTJ3gx13"
      },
      "source": [
        "### **Solamente para uso en Colab - Autentique su ambiente de notebook**\n",
        "\n",
        "En el caso que estes ejecutando este notebook en un Google Colab, descomenta la siguiente célula para realizar la autenticación de su sesión de notebook con Google Cloud. Este paso es importante **para la utilización del Colab**, asi podemos garantizar que las llamdas a las APIs de Google Cloud funcionen sin problemas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NyKGtVQjgx13",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# import sys\n",
        "\n",
        "# # Additional authentication is required for Google Colab\n",
        "# if \"google.colab\" in sys.modules:\n",
        "#     # Authenticate user to Google Cloud\n",
        "#     from google.colab import auth\n",
        "\n",
        "#     auth.authenticate_user()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DF4l8DTdWgPY"
      },
      "source": [
        "### **Solamente para usos en Colab - define el proyecto en Google Cloud que va a ser utilizado**\n",
        "\n",
        "En el caso que estes ejeccutando este notebook en un Google Colab, descomente la siguiente célula para definir que proyecto en Google Cloud sera utilizado por el Colab en la ejecución de este notebook. De lo contrario, continue con los próximos pasos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nqwi-5ufWp_B",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# if \"google.colab\" in sys.modules:\n",
        "#     # Define project information\n",
        "#     PROJECT_ID = \"[your-project-id]\"  # @param {type:\"string\"}\n",
        "#     LOCATION = \"us-central1\"  # @param {type:\"string\"}\n",
        "\n",
        "#     # Initialize Vertex AI\n",
        "#     import vertexai\n",
        "\n",
        "#     vertexai.init(project=PROJECT_ID, location=LOCATION)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jXHfaVS66_01"
      },
      "source": [
        "### Importe las bibliotecas necesarias"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lslYAvw37JGQ",
        "tags": []
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
        "\n",
        "import warnings\n",
        "warnings.simplefilter(\"ignore\", UserWarning)\n",
        "\n",
        "from vertexai.generative_models import (\n",
        "    GenerationConfig,\n",
        "    GenerativeModel,\n",
        "    Image,\n",
        "    Part,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4437b7608c8e"
      },
      "source": [
        "## Importe el modelo `Gemini 1.0 Pro`\n",
        "\n",
        "Gemini Pro (`gemini-1.0-pro`) ayuda en la realización de tareas utilizando lenguage natural, chats multiturno de texto y código e para la generación de código."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2998506fe6d1",
        "tags": []
      },
      "outputs": [],
      "source": [
        "model = GenerativeModel(\"gemini-1.0-pro\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AIl7R_jBUsaC"
      },
      "source": [
        "### Genere textos a partir de prompts de texto\n",
        "\n",
        "Envia un prompt de texto para el modelo. El modelo Gemini Pro (`gemini-pro`) ofrece un mecanismo de respuesta en streaming. De esta manera, no necesitas esperar por la respuesta completa, puedes comenzar a procesar fragmentos tan pronto esten accesibles."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eAo-UsfZECGF",
        "tags": []
      },
      "outputs": [],
      "source": [
        "responses = model.generate_content(\"¿Por qué el cielo es azul?\", stream=True)\n",
        "\n",
        "for response in responses:\n",
        "    print(response.text, end=\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Us8idXnVyQ97"
      },
      "source": [
        "#### Prueba tus propios prompts\n",
        "\n",
        "- ¿Cuáles son los mayores desafios que el sector de salud enfrenta?\n",
        "- ¿Cuáles son los últimos avances en la industria del automóvil?\n",
        "- ¿Cuáles son las mayores oportunidades en el sector minorista?\n",
        "- (¡Prueba con tus propias instrucciones!)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MmAZQW1GyQ97",
        "tags": []
      },
      "outputs": [],
      "source": [
        "prompt = \"\"\" Crea una lista enumerada de 10 items. Cada item de la lista de ser una tendencia en la industria de la tecnología.\n",
        "\n",
        "Cada tendencia debe tener menos de 5 palabras\"\"\" # Prueba con tu propio prompt\n",
        "\n",
        "responses = model.generate_content(prompt, stream=True)\n",
        "\n",
        "for response in responses:\n",
        "    print(response.text, end=\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tDK4XLdz3Oqv"
      },
      "source": [
        "#### Parametros del modelo\n",
        "\n",
        "Cada prompt enviado al modelo incluye valores y parametros que controlan como el modelo genera respuestas. El modelo puede generar resultados diferentes para valores de parametros diferentes. Puedes probar diferentes parametros del modelo para ver como los resultados cambian.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s_2ann-F3WTo",
        "tags": []
      },
      "outputs": [],
      "source": [
        "generation_config = GenerationConfig(\n",
        "    temperature=0.9, # cambie esta variable para probar diferentes temperaturas (entre 0 e 1.0)\n",
        "    top_p=1.0, # cambie esta variable para probar top_p diferentes (entre 0.1 e 1.0)\n",
        "    top_k=32, # cambie esta variable para probar top_k diferentes (entre 1 e 40)\n",
        "    candidate_count=1,\n",
        "    max_output_tokens=8192, # cambie esta variable para probar diferentes tamaños de respuesta (entre 1 y 8192 para Gemini-Pro)\n",
        ")\n",
        "\n",
        "responses = model.generate_content(\n",
        "    \"¿Por qué el cielo es azul?\",\n",
        "    generation_config=generation_config,\n",
        "    stream=True,\n",
        ")\n",
        "\n",
        "for response in responses:\n",
        "    print(response.text, end=\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ga0xM9z9fAnR"
      },
      "source": [
        "### Probemos los prompts de chat\n",
        "\n",
        "El modelo Gemini Pro ofrece soporte a chats com varios turnos y es ideal para tareas de texto que exigen interacciones de ida y vuelta. Los siguientes ejemplos muestran como el modelo responde durante una conversación multiturnos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SFbGVflTfBBk",
        "tags": []
      },
      "outputs": [],
      "source": [
        "chat = model.start_chat()\n",
        "\n",
        "prompt = \"\"\"Mi nombre es Alvaro. Tú eres mi asistente personal. Mis películas favoritas son El señor de los Anillos y El Hobbit.\n",
        "\n",
        "Sugiereme otra película que me podría gustar.\n",
        "\"\"\"\n",
        "\n",
        "responses = chat.send_message(prompt, stream=True)\n",
        "\n",
        "for response in responses:\n",
        "    print(response.text, end=\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZP_z_Oh1J4nk"
      },
      "source": [
        "Este prompt de acompañamiento muestra como el modelo responde con base en el prompt anterior:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OCq7JNBKJrI8",
        "tags": []
      },
      "outputs": [],
      "source": [
        "prompt = \"¿Qué tienen estas películas en común con las películas que me gustan?\"\n",
        "\n",
        "responses = chat.send_message(prompt, stream=True)\n",
        "\n",
        "for response in responses:\n",
        "    print(response.text, end=\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A9iWVspsQp7P"
      },
      "source": [
        "También puedes tener acceso al histórico del chat:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "yK5KhF9jQp7P"
      },
      "outputs": [],
      "source": [
        "print(chat.history)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OK6TsnYghrQk"
      },
      "source": [
        "## Importe el modelo Gemini 1.0 Pro Vision\n",
        "\n",
        "Gemini Pro Vision (`gemini-pro-vision`) es un modelo multimodal que soporta prompts multimodales. Puedes incluir texto, imagen(es) y video en los prompt y obtener respuestas en texto o código."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lRyTw2iPhEXG",
        "tags": []
      },
      "outputs": [],
      "source": [
        "multimodal_model = GenerativeModel(\"gemini-1.0-pro-vision\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lwvfMDEDVyKI"
      },
      "source": [
        "### Define algunas funciones auxiliares\n",
        "\n",
        "Define funciones auxiliares para cargar y mostrar imágenes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NQS13DI6Pjp6",
        "tags": []
      },
      "outputs": [],
      "source": [
        "import http.client\n",
        "import typing\n",
        "import urllib.request\n",
        "\n",
        "import IPython.display\n",
        "from PIL import Image as PIL_Image\n",
        "from PIL import ImageOps as PIL_ImageOps\n",
        "\n",
        "\n",
        "def display_images(\n",
        "    images: typing.Iterable[Image],\n",
        "    max_width: int = 600,\n",
        "    max_height: int = 350,\n",
        ") -> None:\n",
        "    for image in images:\n",
        "        pil_image = typing.cast(PIL_Image.Image, image._pil_image)\n",
        "        if pil_image.mode != \"RGB\":\n",
        "            # RGB is supported by all Jupyter environments (e.g. RGBA is not yet)\n",
        "            pil_image = pil_image.convert(\"RGB\")\n",
        "        image_width, image_height = pil_image.size\n",
        "        if max_width < image_width or max_height < image_height:\n",
        "            # Resize to display a smaller notebook image\n",
        "            pil_image = PIL_ImageOps.contain(pil_image, (max_width, max_height))\n",
        "        IPython.display.display(pil_image)\n",
        "\n",
        "\n",
        "def get_image_bytes_from_url(image_url: str) -> bytes:\n",
        "    with urllib.request.urlopen(image_url) as response:\n",
        "        response = typing.cast(http.client.HTTPResponse, response)\n",
        "        image_bytes = response.read()\n",
        "    return image_bytes\n",
        "\n",
        "\n",
        "def load_image_from_url(image_url: str) -> Image:\n",
        "    image_bytes = get_image_bytes_from_url(image_url)\n",
        "    return Image.from_bytes(image_bytes)\n",
        "\n",
        "def get_url_from_gcs(gcs_uri: str) -> str:\n",
        "    # converts gcs uri to url for image display.\n",
        "    url = \"https://storage.googleapis.com/\" + gcs_uri.replace(\"gs://\", \"\").replace(\" \", \"%20\")\n",
        "    return url\n",
        "\n",
        "def print_multimodal_prompt(contents: list):\n",
        "    for content in contents:\n",
        "        if isinstance(content, Image):\n",
        "            display_images([content])\n",
        "        elif isinstance(content, Part):\n",
        "            url = get_url_from_gcs(content.file_data.file_uri)\n",
        "            IPython.display.display(load_image_from_url(url))\n",
        "        else:\n",
        "            print(content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wy75sLb-yjNn"
      },
      "source": [
        "### Genera texto a partir de imágenes locales\n",
        "\n",
        "Usa el método `Image.load_from_file` para cargar un archivo local como la imagen para la cual generamos texto."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KzqjpEiryjNo",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Download an image from Google Cloud Storage\n",
        "! gsutil cp \"gs://cloud-samples-data/generative-ai/image/320px-Felis_catus-cat_on_snow.jpg\" ./image.jpg\n",
        "\n",
        "# Load from local file\n",
        "image = Image.load_from_file(\"image.jpg\")\n",
        "\n",
        "# Prepare contents\n",
        "prompt = \"Describe esta imagen\"\n",
        "contents = [image, prompt]\n",
        "\n",
        "responses = multimodal_model.generate_content(contents, stream=True)\n",
        "\n",
        "print(\"-------Prompt--------\")\n",
        "print_multimodal_prompt(contents)\n",
        "\n",
        "print(\"\\n-------Respuesta--------\")\n",
        "for response in responses:\n",
        "    print(response.text, end=\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_XvWbyk3Qp7Q"
      },
      "source": [
        "### Generar texto a partir de texto e imágenes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GJvME8gV2nyk"
      },
      "source": [
        "#### Imágenes con URIs de Cloud Storage\n",
        "\n",
        "Si tus imagenes están almacenadas en [Cloud Storage](https://cloud.google.com/storage/docs), puedes especificar la URI de Cloud Storage de la imágen para incluirlo en el prompt. También debes especificar el campo `mime_type`. Los tipos MIME soportados para imagenes incluyen `image/png` e `image/jpeg`.\n",
        "\n",
        "Observe que la URI (no debe ser confundida con URL) de un objeto de Cloud Storage debe siempre comenzar con `gs://`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "YGfc1fefQp7W"
      },
      "outputs": [],
      "source": [
        "# Load image from Cloud Storage URI\n",
        "gcs_uri = \"gs://cloud-samples-data/generative-ai/image/boats.jpeg\"\n",
        "\n",
        "# Prepare contents\n",
        "image = Part.from_uri(gcs_uri, mime_type=\"image/jpeg\")\n",
        "prompt = \"Describe esta escena\"\n",
        "contents = [image, prompt]\n",
        "\n",
        "responses = multimodal_model.generate_content(contents, generation_config=GenerationConfig(temperature=0.0), stream=True)\n",
        "\n",
        "print(\"-------Prompt--------\")\n",
        "print_multimodal_prompt(contents)\n",
        "\n",
        "print(\"\\n-------Respuesta--------\")\n",
        "for response in responses:\n",
        "    print(response.text, end=\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vCHznDDFQp7X"
      },
      "source": [
        "#### Imágenes con links directos\n",
        "\n",
        "También puedes usar links directos para imágenes, conforme se muestra abajo. La función auxiliar `load_image_from_url()` (que fue declarada anteriormente) convierte la imagen en bytes e la retorna como un objeto Image que puede ser enviado a  `Gemini Pro Vision` junto con el prompt de texto."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "bOAuquMWQp7X"
      },
      "outputs": [],
      "source": [
        "# Load image from Cloud Storage URI\n",
        "image_url = (\n",
        "    \"https://storage.googleapis.com/cloud-samples-data/generative-ai/image/boats.jpeg\"\n",
        ")\n",
        "image = load_image_from_url(image_url) # convert to bytes\n",
        "\n",
        "# Prepare contents\n",
        "prompt = \"Describe esta escena\"\n",
        "contents = [image, prompt]\n",
        "\n",
        "responses = multimodal_model.generate_content(contents, generation_config=GenerationConfig(temperature=0.0), stream=True)\n",
        "\n",
        "print(\"-------Prompt--------\")\n",
        "print_multimodal_prompt(contents)\n",
        "\n",
        "print(\"\\n-------Respuesta--------\")\n",
        "for response in responses:\n",
        "    print(response.text, end=\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YmlmaLEpQp7X"
      },
      "source": [
        "#### Combinando várias imágenes y texto en un prompt *few-shot*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4JWW1kKrQp7X"
      },
      "source": [
        "Puedes enviar más de una imagen por vez y colocarlos en cualquier lugar al lado de um prompt de texto.\n",
        "\n",
        "En el ejemplo, la solicitación con algunas fotos es ejecutada para que o `Gemini Pro Vision` retorne la ciudad y los puntos de referencia en un formato JSON específico."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VfU7Qlz1hAEA",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Load images from Cloud Storage URI\n",
        "image1_url = \"https://storage.googleapis.com/github-repo/img/gemini/intro/landmark1.jpg\"\n",
        "image2_url = \"https://storage.googleapis.com/github-repo/img/gemini/intro/landmark2.jpg\"\n",
        "image3_url = \"https://storage.googleapis.com/github-repo/img/gemini/intro/landmark3.jpg\"\n",
        "image1 = load_image_from_url(image1_url)\n",
        "image2 = load_image_from_url(image2_url)\n",
        "image3 = load_image_from_url(image3_url)\n",
        "\n",
        "# Prepare prompts\n",
        "prompt1 = \"\"\"{\"ciudad\": \"Londres\", \"punto_turistico:\", \"Big Ben\"}\"\"\"\n",
        "prompt2 = \"\"\"{\"ciudad\": \"Paris\", \"punto_turistico:\", \"Torre Eiffel\"}\"\"\"\n",
        "\n",
        "# Prepare contents\n",
        "contents = [image1, prompt1, image2, prompt2, image3]\n",
        "\n",
        "responses = multimodal_model.generate_content(contents, stream=True)\n",
        "\n",
        "print(\"-------Prompt--------\")\n",
        "print_multimodal_prompt(contents)\n",
        "\n",
        "print(\"\\n-------Respuesta--------\")\n",
        "for response in responses:\n",
        "    print(response.text, end=\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vyjpi1fB7mgj"
      },
      "source": [
        "### Genere texto a partir de un archivo de video\n",
        "\n",
        "Especifique la URI de Cloud Storage de un video que sera incluído en el prompt.\n",
        "También debes especificar el campo `mime_type`. El tipo MIME soportado para videos incluye `video/mp4`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "woO7EDmZQp7Y"
      },
      "outputs": [],
      "source": [
        "file_path = \"github-repo/img/gemini/multimodality_usecases_overview/pixel8.mp4\"\n",
        "video_uri = f\"gs://{file_path}\"\n",
        "video_url = f\"https://storage.googleapis.com/{file_path}\"\n",
        "\n",
        "IPython.display.Video(video_url, width=450)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VXX1jLXq7ojB",
        "tags": []
      },
      "outputs": [],
      "source": [
        "prompt = \"\"\"\n",
        "Responde las siguientes preguntas usando apenas el video:\n",
        "¿Cuál es la profesión de la persona principal del video?\n",
        "¿Cuales son las principales funcionalidades del telefono que son presentadas en este video?\n",
        "¿En qué ciudad fue grabado?\n",
        "\n",
        "Retorna la respuesta en formato JSON.\n",
        "\"\"\"\n",
        "\n",
        "video = Part.from_uri(video_uri, mime_type=\"video/mp4\")\n",
        "contents = [prompt, video]\n",
        "\n",
        "responses = multimodal_model.generate_content(contents, stream=True)\n",
        "\n",
        "for response in responses:\n",
        "    print(response.text, end=\"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ch3kO-jzQp7Y"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "environment": {
      "kernel": "python3",
      "name": "tf2-cpu.2-11.m117",
      "type": "gcloud",
      "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/tf2-cpu.2-11:m117"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}