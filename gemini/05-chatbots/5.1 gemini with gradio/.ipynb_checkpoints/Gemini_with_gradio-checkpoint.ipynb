{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ijGzTHJJUCPY"
   },
   "outputs": [],
   "source": [
    "# Copyright 2023 Google LLC\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VEqbX8OhE8y9"
   },
   "source": [
    "# Construyendo un chatbot con Gemini y gradio\n",
    "\n",
    "<table align=\"left\">\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://colab.research.google.com/github/GoogleCloudPlatform/generative-ai/blob/main/gemini/getting-started/intro_gemini_python.ipynb\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/colab-logo-32px.png\" alt=\"Google Colaboratory logo\"><br> Ejecutar en Colab\n",
    "    </a>\n",
    "  </td>\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/getting-started/intro_gemini_python.ipynb\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/github-logo-32px.png\" alt=\"GitHub logo\"><br> Ver en GitHub\n",
    "    </a>\n",
    "  </td>\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https://raw.githubusercontent.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/getting-started/intro_gemini_python.ipynb\">\n",
    "      <img src=\"https://lh3.googleusercontent.com/UiNooY4LUgW_oTvpsNhPpQzsstV5W8F7rYgxgGBD85cWJoLmrOzhVs_ksK_vgx40SHs7jCqkTkCk=e14-rj-sc0xffffff-h130-w32\" alt=\"Vertex AI logo\"><br> Abrir en la Vertex AI workbench\n",
    "    </a>\n",
    "  </td>\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CkHPv2myT2cx"
   },
   "source": [
    "## Visi칩n general\n",
    "\n",
    "### Gemini\n",
    "\n",
    "Gemini es una familia de modelos de IA generativa desarrollados por Google DeepMind y dise침ados para casos de uso multimodales. La API de Gemini proporciona acceso a los modelos Gemini Pro Vision y Gemini Pro.\n",
    "\n",
    "### API de Gemini de Vertex AI\n",
    "\n",
    "La API Vertex AI Gemini proporciona una interfaz unificada para interactuar con los modelos Gemini. Actualmente hay dos modelos disponibles en la API de Gemini:\n",
    "\n",
    "- **Modelo Gemini Pro** (`gemini-pro`): Dise침ado para manejar tareas de lenguaje natural, chat de texto y c칩digo de m칰ltiples turnos y generaci칩n de c칩digo.\n",
    "- **Modelo Gemini Pro Vision** (`gemini-pro-vision`): admite indicaciones multimodales. Puede incluir texto, im치genes y videos en sus solicitudes r치pidas y obtener respuestas en texto o c칩digo.\n",
    "\n",
    "Puede interactuar con la API de Gemini utilizando los siguientes m칠todos:\n",
    "\n",
    "- Utilice [Vertex AI Studio](https://cloud.google.com/generative-ai-studio) para realizar pruebas r치pidas y generar comandos\n",
    "- Utilice el SDK de Vertex AI\n",
    "\n",
    "### calificaci칩n\n",
    "\n",
    "Gradio es una biblioteca de Python que le permite crear r치pidamente aplicaciones web personalizables. En esta pr치ctica de laboratorio, usaremos la biblioteca para crear un chatbot que utilice las capacidades multimodales del modelo Gemini. M치s detalles sobre Gradio en la [p치gina oficial del proyecto] (https://www.gradio.app).\n",
    "\n",
    "Este cuaderno se centra en el uso del **Vertex AI SDK para Python** para llamar a la API Vertex AI Gemini.\n",
    "\n",
    "Para obtener m치s informaci칩n, consulte la documentaci칩n [IA generativa en Vertex AI] (https://cloud.google.com/vertex-ai/docs/generative-ai/learn/overview)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DrkcqHrrwMAo"
   },
   "source": [
    "### Objetivos\n",
    "\n",
    "En este tutorial, aprender치 a utilizar la API Vertex AI Gemini con el SDK Vertex AI para Python para interactuar con los modelos Gemini Pro (`gemini-pro`) y Gemini Pro Vision (`gemini-pro-vision`).\n",
    "\n",
    "Completar치s las siguientes tareas:\n",
    "\n",
    "- Instale el SDK de Vertex AI para Python\n",
    "- Utilice la API Vertex AI Gemini para interactuar con cada modelo\n",
    "    - Modelo Gemini Pro (`gemini-pro`):\n",
    "      - Generar texto a partir de indicaciones de texto.\n",
    "      - Explore varias funciones y opciones de configuraci칩n\n",
    "    - Modelo Gemini Pro Vision (`gemini-pro-vision`):\n",
    "      - Generar texto a partir de im치genes y mensajes de texto.\n",
    "      - Generar texto a partir de videos y mensajes de texto.\n",
    "- Crear una aplicaci칩n con Gradio\n",
    "    - Interactuar con el modelo Gemini a trav칠s de la aplicaci칩n Gradio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C9nEPojogw-g"
   },
   "source": [
    "### Costos\n",
    "\n",
    "Este tutorial utiliza los siguientes componentes de Google Cloud que pueden generar cargos en su factura:\n",
    "\n",
    "- Artifacts Registry\n",
    "- Cloud Build\n",
    "- Cloud Run\n",
    "- Vertex AI\n",
    "\n",
    "Obtenga m치s informaci칩n sobre los servicios utilizando la [calculadora de precios](https://cloud.google.com/products/calculator/) para generar una estimaci칩n de costos basada en el uso proyectado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r11Gu7qNgx1p"
   },
   "source": [
    "## Primeros pasos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "No17Cw5hgx12"
   },
   "source": [
    "### Instalar el SDK de Vertex AI\n",
    "**Importante:** solo descomente la l칤nea a continuaci칩n si **no** est치 ejecutando esta pr치ctica de laboratorio en Qwiklabs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tFy3H3aPgx12",
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ! pip3 install --upgrade --user google-cloud-aiplatform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j7UyNVSiyQ96",
    "tags": []
   },
   "source": [
    "### **Reinicie el kernel de su Jupyter notebook**\n",
    "\n",
    "Como la instalaci칩n se realiza con la opci칩n `--user`, es necesario reiniciar el kernel para que los nuevos m칩dulos sean accesibles.\n",
    "\n",
    "**Importante:** solo descomente la l칤nea a continuaci칩n si **no** est치 ejecutando esta pr치ctica de laboratorio en Qwiklabs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YmY9HVVGSBW5",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import IPython\n",
    "\n",
    "# app = IPython.Application.instance()\n",
    "# app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>丘멆잺 Se est치 reiniciando el kernel del notebook. Espere a que se complete este proceso antes de continuar con los siguientes pasos. 丘멆잺</b>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dmWOrTJ3gx13"
   },
   "source": [
    "### **Solo para uso en Colab: autentique tu notebook**\n",
    "\n",
    "En caso de que est칠s ejecutando este notebook en Google Colab, descomente esta celda para realizar la autenticaci칩n de tu sesi칩n de notebook con Google Cloud. Este paso es importante **para utilizar no Colab** para garantizar que las API de Google Cloud funcionen Sem problemas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NyKGtVQjgx13",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import sys\n",
    "\n",
    "# # Additional authentication is required for Google Colab\n",
    "# if \"google.colab\" in sys.modules:\n",
    "#     # Authenticate user to Google Cloud\n",
    "#     from google.colab import auth\n",
    "\n",
    "#     auth.authenticate_user()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DF4l8DTdWgPY"
   },
   "source": [
    "### **Solo para uso en Colab: define el proyecto Google Cloud para ser utilizado**\n",
    "\n",
    "Si est치s ejecutando este notebook en Google Colab, descomente esta celda baja para definir qu칠 proyecto Google Cloud se utilizar치 en Colab en la ejecuci칩n de este notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Nqwi-5ufWp_B",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# if \"google.colab\" in sys.modules:\n",
    "#     # Define project information\n",
    "#     PROJECT_ID = \"[your-project-id]\"  # @param {type:\"string\"}\n",
    "#     LOCATION = \"us-central1\"  # @param {type:\"string\"}\n",
    "\n",
    "#     # Initialize Vertex AI\n",
    "#     import vertexai\n",
    "\n",
    "#     vertexai.init(project=PROJECT_ID, location=LOCATION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iniciar servicios requeridos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!gcloud services enable cloudbuild.googleapis.com\n",
    "!gcloud services enable artifactregistry.googleapis.com\n",
    "!gcloud services enable run.googleapis.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configurar la CLI de Google Cloud (`gcloud`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### configuraci칩n PROJECT_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "shell_output = ! gcloud config list --format 'value(core.project)' 2>/dev/null\n",
    "PROJECT_ID = shell_output[0]\n",
    "print(\"Project ID:\", PROJECT_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Configuraci칩n de la regi칩n que se utilizar치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "REGION = \"us-central1\"\n",
    "\n",
    "if REGION == \"[your-region]\":\n",
    "    REGION = \"us-central1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creando el servicio que usaremos con Gradio\n",
    "\n",
    "**Importante:** Actualice las variables `PROJECT_ID` y `LOCATION` antes de continuar. Los valores que debes ingresar son los siguientes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(f\"PROJECT_ID: {PROJECT_ID}\")\n",
    "print(f\"REGION: {REGION}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%writefile main.py\n",
    "\n",
    "import os\n",
    "import time\n",
    "import base64\n",
    "import gradio as gr\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\", UserWarning)\n",
    "\n",
    "import vertexai\n",
    "from vertexai.generative_models import (\n",
    "    GenerativeModel,\n",
    "    Image\n",
    ")\n",
    "\n",
    "# cabe칞alho da p치gina\n",
    "TITLE = \"\"\"<h1 align=\"center\">Chatbot com Gemini 游뱄</h1>\"\"\"\n",
    "SUBTITLE = \"\"\"<h2 align=\"center\">Prot칩tipo de um chatbot multimodal com Gemini e Gradio</h2>\"\"\"\n",
    "\n",
    "# variaveis de projeto e regiao\n",
    "PROJECT_ID=\"[nome do seu projeto]\" # TODO: atualize para o seu PROJECT_ID\n",
    "LOCATION=\"[regi칚o a ser utilizado]\" # TODO: atualize para o seu REGION\n",
    "\n",
    "# inicializando a SDK da Vertex AI\n",
    "vertexai.init(project=PROJECT_ID, location=LOCATION)\n",
    "\n",
    "# instanciando os clientes de Gemini e Gemini-Pro\n",
    "model = GenerativeModel(\"gemini-1.0-pro\")\n",
    "multimodal_model = GenerativeModel(\"gemini-1.0-pro-vision\")\n",
    "\n",
    "\n",
    "# converte imagens para formato base64\n",
    "def image_to_base64(image_path):\n",
    "    with open(image_path, 'rb') as img:\n",
    "        encoded_string = base64.b64encode(img.read())\n",
    "    return encoded_string.decode('utf-8')\n",
    "\n",
    "\n",
    "# mostra a entrada do usuario no historico do chatbot\n",
    "def query_message(history,txt,img):\n",
    "    if not img:\n",
    "        history += [(txt,None)]\n",
    "        return history\n",
    "    print(\"imagem recebida:\")\n",
    "    print(img)\n",
    "    base64 = image_to_base64(img)\n",
    "    data_url = f\"data:image/jpeg;base64,{base64}\"\n",
    "    history += [(f\"{txt} ![]({data_url})\", None)]\n",
    "    return history\n",
    "    \n",
    "# usa o input do usuario, interage com o Gemini, gera resposta \n",
    "# e mostra no historico do chatbot\n",
    "def llm_response(history,text,img):\n",
    "    if not img:\n",
    "        response = model.generate_content(text)\n",
    "        history += [(None,response.text)]\n",
    "        return history\n",
    "    else:\n",
    "        print(\"imagem no llm_response:\")\n",
    "        print(img)\n",
    "        try:\n",
    "            img = Image.load_from_file(img)\n",
    "            response = multimodal_model.generate_content([text,img])\n",
    "            print(\"resposta da chamada de API:\")\n",
    "            print(response.text)\n",
    "            history += [(None,response.text)]\n",
    "            return history\n",
    "        except Exception as e:\n",
    "            print(\"deu erro na llm_response\")\n",
    "            print(str(e))\n",
    "            return history\n",
    "    \n",
    "    \n",
    "# interface do gradio\n",
    "print(\"Iniciando a constru칞칚o da app gradio...\")\n",
    "with gr.Blocks() as app:\n",
    "    gr.HTML(TITLE)\n",
    "    gr.HTML(SUBTITLE)\n",
    "    with gr.Row():\n",
    "        image_box = gr.Image(type=\"filepath\")\n",
    "        chatbot = gr.Chatbot(\n",
    "            scale = 2,\n",
    "            height=750\n",
    "        )\n",
    "        \n",
    "    text_box = gr.Textbox(\n",
    "            placeholder=\"Digite sua mensagem e tecle enter ou fa칞a o upload de uma imagem\",\n",
    "            container=False,\n",
    "        )\n",
    "\n",
    "    btn = gr.Button(\"Enviar\")\n",
    "    clicked = btn.click(query_message,\n",
    "                        [chatbot,text_box,image_box],\n",
    "                        chatbot\n",
    "                        ).then(llm_response,\n",
    "                                [chatbot,text_box,image_box],\n",
    "                                chatbot\n",
    "                                )\n",
    "\n",
    "app.queue()\n",
    "app.launch(server_name=\"0.0.0.0\", server_port=7860)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4437b7608c8e"
   },
   "source": [
    "### Definiendo el `Dockerfile` que usaremos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2998506fe6d1",
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%writefile Dockerfile\n",
    "\n",
    "FROM python:3.8\n",
    "\n",
    "EXPOSE 8080\n",
    "WORKDIR /app\n",
    "\n",
    "COPY . ./\n",
    "\n",
    "EXPOSE 7860\n",
    "\n",
    "RUN pip install -r requirements.txt\n",
    "\n",
    "ENTRYPOINT [\"python\", \"main.py\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AIl7R_jBUsaC"
   },
   "source": [
    "### Creando la imagen del contenedor que usaremos en el laboratorio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "!gcloud artifacts repositories create gemini-gradio-repo --repository-format=docker --location=$REGION\n",
    "!gcloud builds submit --tag us-central1-docker.pkg.dev/$PROJECT_ID/gemini-gradio-repo/gemini-gradio-app"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creando la aplicaci칩n en Cloud Run\n",
    "\n",
    "B치sicamente lo que se est치 haciendo aqu칤 es:\n",
    "- Creando un servicio en Cloud Run llamado `gemini-gradio-app`\n",
    "- Utilizar치 la imagen del contenedor que se cre칩 anteriormente: `us-central1-docker.pkg.dev/<PROJECT_ID>/gemini-gradio-repo/gemini-gradio-app`\n",
    "- Permitir치 el acceso no autenticado con la cl치usula `--allow-unauthenticated`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "!gcloud run deploy gemini-gradio-app --port 7860 --image us-central1-docker.pkg.dev/$PROJECT_ID/gemini-gradio-repo/gemini-gradio-app --allow-unauthenticated --region=us-central1 --platform=managed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accediendo a tu servicio\n",
    "\n",
    "Al finalizar de ejecutar la celda anterior, quedar치 la siguiente informaci칩n:\n",
    "\n",
    "`URL de servicio: https://gemini-gradio-app-XXX-uc.a.run.app`\n",
    "\n",
    "Copie esta URL en una nueva pesta침a del navegador y acceda a su aplicaci칩n Gradio con Gemini."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "environment": {
   "kernel": "python3",
   "name": "tf2-cpu.2-11.m117",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/tf2-cpu.2-11:m117"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
