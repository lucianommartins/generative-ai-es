{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ijGzTHJJUCPY"
   },
   "outputs": [],
   "source": [
    "# Copyright 2023 Google LLC\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VEqbX8OhE8y9"
   },
   "source": [
    "# Construyendo un chatbot con Gemini y gradio\n",
    "\n",
    "<table align=\"left\">\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://colab.research.google.com/github/GoogleCloudPlatform/generative-ai/blob/main/gemini/getting-started/intro_gemini_python.ipynb\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/colab-logo-32px.png\" alt=\"Google Colaboratory logo\"><br> Ejecutar en Colab\n",
    "    </a>\n",
    "  </td>\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/getting-started/intro_gemini_python.ipynb\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/github-logo-32px.png\" alt=\"GitHub logo\"><br> Ver en GitHub\n",
    "    </a>\n",
    "  </td>\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https://raw.githubusercontent.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/getting-started/intro_gemini_python.ipynb\">\n",
    "      <img src=\"https://lh3.googleusercontent.com/UiNooY4LUgW_oTvpsNhPpQzsstV5W8F7rYgxgGBD85cWJoLmrOzhVs_ksK_vgx40SHs7jCqkTkCk=e14-rj-sc0xffffff-h130-w32\" alt=\"Vertex AI logo\"><br> Abrir en la Vertex AI workbench\n",
    "    </a>\n",
    "  </td>\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CkHPv2myT2cx"
   },
   "source": [
    "## Visión general\n",
    "\n",
    "### Gemini\n",
    "\n",
    "Gemini es una familia de modelos de IA generativa desarrollados por Google DeepMind y diseñados para casos de uso multimodales. La API de Gemini proporciona acceso a los modelos Gemini Pro Vision y Gemini Pro.\n",
    "\n",
    "### API de Gemini de Vertex AI\n",
    "\n",
    "La API Vertex AI Gemini proporciona una interfaz unificada para interactuar con los modelos Gemini. Actualmente hay dos modelos disponibles en la API de Gemini:\n",
    "\n",
    "- **Modelo Gemini Pro** (`gemini-pro`): Diseñado para manejar tareas de lenguaje natural, chat de texto y código de múltiples turnos y generación de código.\n",
    "- **Modelo Gemini Pro Vision** (`gemini-pro-vision`): admite indicaciones multimodales. Puede incluir texto, imágenes y videos en sus solicitudes rápidas y obtener respuestas en texto o código.\n",
    "\n",
    "Puede interactuar con la API de Gemini utilizando los siguientes métodos:\n",
    "\n",
    "- Utilice [Vertex AI Studio](https://cloud.google.com/generative-ai-studio) para realizar pruebas rápidas y generar comandos\n",
    "- Utilice el SDK de Vertex AI\n",
    "\n",
    "### calificación\n",
    "\n",
    "Gradio es una biblioteca de Python que le permite crear rápidamente aplicaciones web personalizables. En esta práctica de laboratorio, usaremos la biblioteca para crear un chatbot que utilice las capacidades multimodales del modelo Gemini. Más detalles sobre Gradio en la [página oficial del proyecto] (https://www.gradio.app).\n",
    "\n",
    "Este cuaderno se centra en el uso del **Vertex AI SDK para Python** para llamar a la API Vertex AI Gemini.\n",
    "\n",
    "Para obtener más información, consulte la documentación [IA generativa en Vertex AI] (https://cloud.google.com/vertex-ai/docs/generative-ai/learn/overview)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DrkcqHrrwMAo"
   },
   "source": [
    "### Objetivos\n",
    "\n",
    "En este tutorial, aprenderá a utilizar la API Vertex AI Gemini con el SDK Vertex AI para Python para interactuar con los modelos Gemini Pro (`gemini-pro`) y Gemini Pro Vision (`gemini-pro-vision`).\n",
    "\n",
    "Completarás las siguientes tareas:\n",
    "\n",
    "- Instale el SDK de Vertex AI para Python\n",
    "- Utilice la API Vertex AI Gemini para interactuar con cada modelo\n",
    "    - Modelo Gemini Pro (`gemini-pro`):\n",
    "      - Generar texto a partir de indicaciones de texto.\n",
    "      - Explore varias funciones y opciones de configuración\n",
    "    - Modelo Gemini Pro Vision (`gemini-pro-vision`):\n",
    "      - Generar texto a partir de imágenes y mensajes de texto.\n",
    "      - Generar texto a partir de videos y mensajes de texto.\n",
    "- Crear una aplicación con Gradio\n",
    "    - Interactuar con el modelo Gemini a través de la aplicación Gradio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C9nEPojogw-g"
   },
   "source": [
    "### Costos\n",
    "\n",
    "Este tutorial utiliza los siguientes componentes de Google Cloud que pueden generar cargos en su factura:\n",
    "\n",
    "- Artifacts Registry\n",
    "- Cloud Build\n",
    "- Cloud Run\n",
    "- Vertex AI\n",
    "\n",
    "Obtenga más información sobre los servicios utilizando la [calculadora de precios](https://cloud.google.com/products/calculator/) para generar una estimación de costos basada en el uso proyectado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r11Gu7qNgx1p"
   },
   "source": [
    "## Primeros pasos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "No17Cw5hgx12"
   },
   "source": [
    "### Instalar el SDK de Vertex AI\n",
    "**Importante:** solo descomente la línea a continuación si **no** está ejecutando esta práctica de laboratorio en Qwiklabs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tFy3H3aPgx12",
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ! pip3 install --upgrade --user google-cloud-aiplatform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j7UyNVSiyQ96",
    "tags": []
   },
   "source": [
    "### **Reinicie el kernel de su Jupyter notebook**\n",
    "\n",
    "Como la instalación se realiza con la opción `--user`, es necesario reiniciar el kernel para que los nuevos módulos sean accesibles.\n",
    "\n",
    "**Importante:** solo descomente la línea a continuación si **no** está ejecutando esta práctica de laboratorio en Qwiklabs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YmY9HVVGSBW5",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import IPython\n",
    "\n",
    "# app = IPython.Application.instance()\n",
    "# app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>⚠️ Se está reiniciando el kernel del notebook. Espere a que se complete este proceso antes de continuar con los siguientes pasos. ⚠️</b>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dmWOrTJ3gx13"
   },
   "source": [
    "### **Solo para uso en Colab: autentique tu notebook**\n",
    "\n",
    "En caso de que estés ejecutando este notebook en Google Colab, descomente esta celda para realizar la autenticación de tu sesión de notebook con Google Cloud. Este paso es importante **para utilizar no Colab** para garantizar que las API de Google Cloud funcionen Sem problemas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NyKGtVQjgx13",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import sys\n",
    "\n",
    "# # Additional authentication is required for Google Colab\n",
    "# if \"google.colab\" in sys.modules:\n",
    "#     # Authenticate user to Google Cloud\n",
    "#     from google.colab import auth\n",
    "\n",
    "#     auth.authenticate_user()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DF4l8DTdWgPY"
   },
   "source": [
    "### **Solo para uso en Colab: define el proyecto Google Cloud para ser utilizado**\n",
    "\n",
    "Si estás ejecutando este notebook en Google Colab, descomente esta celda baja para definir qué proyecto Google Cloud se utilizará en Colab en la ejecución de este notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Nqwi-5ufWp_B",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# if \"google.colab\" in sys.modules:\n",
    "#     # Define project information\n",
    "#     PROJECT_ID = \"[your-project-id]\"  # @param {type:\"string\"}\n",
    "#     LOCATION = \"us-central1\"  # @param {type:\"string\"}\n",
    "\n",
    "#     # Initialize Vertex AI\n",
    "#     import vertexai\n",
    "\n",
    "#     vertexai.init(project=PROJECT_ID, location=LOCATION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iniciar servicios requeridos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!gcloud services enable cloudbuild.googleapis.com\n",
    "!gcloud services enable artifactregistry.googleapis.com\n",
    "!gcloud services enable run.googleapis.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configurar la CLI de Google Cloud (`gcloud`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### configuración PROJECT_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "shell_output = ! gcloud config list --format 'value(core.project)' 2>/dev/null\n",
    "PROJECT_ID = shell_output[0]\n",
    "print(\"Project ID:\", PROJECT_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Configuración de la región que se utilizará"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "REGION = \"us-central1\"\n",
    "\n",
    "if REGION == \"[your-region]\":\n",
    "    REGION = \"us-central1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creando el servicio que usaremos con Gradio\n",
    "\n",
    "**Importante:** Actualice las variables `PROJECT_ID` y `LOCATION` antes de continuar. Los valores que debes ingresar son los siguientes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(f\"PROJECT_ID: {PROJECT_ID}\")\n",
    "print(f\"REGION: {REGION}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%writefile main.py\n",
    "\n",
    "import os\n",
    "import time\n",
    "import base64\n",
    "import gradio as gr\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\", UserWarning)\n",
    "\n",
    "import vertexai\n",
    "from vertexai.generative_models import (\n",
    "    GenerativeModel,\n",
    "    Image\n",
    ")\n",
    "\n",
    "# cabeçalho da página\n",
    "TITLE = \"\"\"<h1 align=\"center\">Chatbot com Gemini 🤖</h1>\"\"\"\n",
    "SUBTITLE = \"\"\"<h2 align=\"center\">Protótipo de um chatbot multimodal com Gemini e Gradio</h2>\"\"\"\n",
    "\n",
    "# variaveis de projeto e regiao\n",
    "PROJECT_ID=\"[nome do seu projeto]\" # TODO: atualize para o seu PROJECT_ID\n",
    "LOCATION=\"[região a ser utilizado]\" # TODO: atualize para o seu REGION\n",
    "\n",
    "# inicializando a SDK da Vertex AI\n",
    "vertexai.init(project=PROJECT_ID, location=LOCATION)\n",
    "\n",
    "# instanciando os clientes de Gemini e Gemini-Pro\n",
    "model = GenerativeModel(\"gemini-1.0-pro\")\n",
    "multimodal_model = GenerativeModel(\"gemini-1.0-pro-vision\")\n",
    "\n",
    "\n",
    "# converte imagens para formato base64\n",
    "def image_to_base64(image_path):\n",
    "    with open(image_path, 'rb') as img:\n",
    "        encoded_string = base64.b64encode(img.read())\n",
    "    return encoded_string.decode('utf-8')\n",
    "\n",
    "\n",
    "# mostra a entrada do usuario no historico do chatbot\n",
    "def query_message(history,txt,img):\n",
    "    if not img:\n",
    "        history += [(txt,None)]\n",
    "        return history\n",
    "    print(\"imagem recebida:\")\n",
    "    print(img)\n",
    "    base64 = image_to_base64(img)\n",
    "    data_url = f\"data:image/jpeg;base64,{base64}\"\n",
    "    history += [(f\"{txt} ![]({data_url})\", None)]\n",
    "    return history\n",
    "    \n",
    "# usa o input do usuario, interage com o Gemini, gera resposta \n",
    "# e mostra no historico do chatbot\n",
    "def llm_response(history,text,img):\n",
    "    if not img:\n",
    "        response = model.generate_content(text)\n",
    "        history += [(None,response.text)]\n",
    "        return history\n",
    "    else:\n",
    "        print(\"imagem no llm_response:\")\n",
    "        print(img)\n",
    "        try:\n",
    "            img = Image.load_from_file(img)\n",
    "            response = multimodal_model.generate_content([text,img])\n",
    "            print(\"resposta da chamada de API:\")\n",
    "            print(response.text)\n",
    "            history += [(None,response.text)]\n",
    "            return history\n",
    "        except Exception as e:\n",
    "            print(\"deu erro na llm_response\")\n",
    "            print(str(e))\n",
    "            return history\n",
    "    \n",
    "    \n",
    "# interface do gradio\n",
    "print(\"Iniciando a construção da app gradio...\")\n",
    "with gr.Blocks() as app:\n",
    "    gr.HTML(TITLE)\n",
    "    gr.HTML(SUBTITLE)\n",
    "    with gr.Row():\n",
    "        image_box = gr.Image(type=\"filepath\")\n",
    "        chatbot = gr.Chatbot(\n",
    "            scale = 2,\n",
    "            height=750\n",
    "        )\n",
    "        \n",
    "    text_box = gr.Textbox(\n",
    "            placeholder=\"Digite sua mensagem e tecle enter ou faça o upload de uma imagem\",\n",
    "            container=False,\n",
    "        )\n",
    "\n",
    "    btn = gr.Button(\"Enviar\")\n",
    "    clicked = btn.click(query_message,\n",
    "                        [chatbot,text_box,image_box],\n",
    "                        chatbot\n",
    "                        ).then(llm_response,\n",
    "                                [chatbot,text_box,image_box],\n",
    "                                chatbot\n",
    "                                )\n",
    "\n",
    "app.queue()\n",
    "app.launch(server_name=\"0.0.0.0\", server_port=7860)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4437b7608c8e"
   },
   "source": [
    "### Definiendo el `Dockerfile` que usaremos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2998506fe6d1",
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%writefile Dockerfile\n",
    "\n",
    "FROM python:3.8\n",
    "\n",
    "EXPOSE 8080\n",
    "WORKDIR /app\n",
    "\n",
    "COPY . ./\n",
    "\n",
    "EXPOSE 7860\n",
    "\n",
    "RUN pip install -r requirements.txt\n",
    "\n",
    "ENTRYPOINT [\"python\", \"main.py\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AIl7R_jBUsaC"
   },
   "source": [
    "### Creando la imagen del contenedor que usaremos en el laboratorio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "!gcloud artifacts repositories create gemini-gradio-repo --repository-format=docker --location=$REGION\n",
    "!gcloud builds submit --tag us-central1-docker.pkg.dev/$PROJECT_ID/gemini-gradio-repo/gemini-gradio-app"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creando la aplicación en Cloud Run\n",
    "\n",
    "Básicamente lo que se está haciendo aquí es:\n",
    "- Creando un servicio en Cloud Run llamado `gemini-gradio-app`\n",
    "- Utilizará la imagen del contenedor que se creó anteriormente: `us-central1-docker.pkg.dev/<PROJECT_ID>/gemini-gradio-repo/gemini-gradio-app`\n",
    "- Permitirá el acceso no autenticado con la cláusula `--allow-unauthenticated`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "!gcloud run deploy gemini-gradio-app --port 7860 --image us-central1-docker.pkg.dev/$PROJECT_ID/gemini-gradio-repo/gemini-gradio-app --allow-unauthenticated --region=us-central1 --platform=managed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accediendo a tu servicio\n",
    "\n",
    "Al finalizar de ejecutar la celda anterior, quedará la siguiente información:\n",
    "\n",
    "`URL de servicio: https://gemini-gradio-app-XXX-uc.a.run.app`\n",
    "\n",
    "Copie esta URL en una nueva pestaña del navegador y acceda a su aplicación Gradio con Gemini."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "environment": {
   "kernel": "python3",
   "name": "tf2-cpu.2-11.m117",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/tf2-cpu.2-11:m117"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
